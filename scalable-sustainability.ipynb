{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d585a98-ed39-44ca-bd6a-1a7e73339cdd",
   "metadata": {},
   "source": [
    "# Scalable Sustainability\n",
    "\n",
    "We'll use the Planetary Computer's hub managed [Dask Gateway](https://gateway.dask.org/) to quickly spin up a Dask cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c571572-6c1d-4fae-81bc-79690db8e4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_gateway import GatewayCluster\n",
    "\n",
    "cluster = GatewayCluster()\n",
    "cluster.scale(64)\n",
    "client = cluster.get_client()\n",
    "\n",
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09988dd-328e-417f-a8b9-83e52f3f5109",
   "metadata": {},
   "source": [
    "## Cloud-free composite\n",
    "\n",
    "This example will create a cloud-free composite of some Sentinel-2 Level 2-A scenes over Redmond, Washington. The Planetary Computer's [STAC API](https://planetarycomputer.microsoft.com/api/stac/v1) helps us find just the scenes we need. Xarray, Dask, and NumPy will do the computation to remove the clouds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a9138a-30a8-47c2-a30f-317068bdb15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio.features\n",
    "import pystac_client\n",
    "\n",
    "bbox = [-122.28, 47.55, -121.96, 47.75]\n",
    "\n",
    "stac = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n",
    ")\n",
    "\n",
    "search = stac.search(\n",
    "    collections=[\"sentinel-2-l2a\"],\n",
    "    bbox=bbox,\n",
    "    datetime=\"2016-01-01/2020-12-31\",\n",
    "    query={\"eo:cloud_cover\": {\"lt\": 25}},\n",
    ")\n",
    "\n",
    "items = list(search.get_items())\n",
    "print(len(items))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e812ca-f6f8-4407-a268-942092f6c9b0",
   "metadata": {},
   "source": [
    "The metadata at https://planetarycomputer.microsoft.com/api/stac/v1 is completely public and anonymously accessible.\n",
    "\n",
    "The Planetary Computer's *data* files, the actual COGS, are typically in private blob storage accounts. But they can be accessed anonymously by signing the items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d632fae1-f26a-43b9-a8c1-bf018f25b8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import planetary_computer\n",
    "\n",
    "signed_items = [\n",
    "    planetary_computer.sign(item).to_dict() for item in items\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708cd485-e1f9-432b-919f-2be9f4ac4385",
   "metadata": {},
   "source": [
    "We'll use `stackstac` to quickly go from STAC items to a DataArray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a36819f-e0eb-4f96-a767-9b851937bf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stackstac\n",
    "\n",
    "data = (\n",
    "    stackstac.stack(\n",
    "        signed_items,\n",
    "        assets=[\"B04\", \"B03\", \"B02\"],  # red, green, blue\n",
    "        chunksize=4096,\n",
    "        resolution=30,\n",
    "    )\n",
    "    .where(lambda x: x > 0)  # sentinel-2 uses 0 as nodata\n",
    "    .assign_coords(band=lambda x: x.common_name.rename(\"band\"))  # use common names\n",
    ")\n",
    "data = data.persist()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e45a01b-9f14-4a90-9dd9-f9d52e330eb8",
   "metadata": {},
   "source": [
    "We'll remove clouds by taking the median over time. We have a timeseries of points at each pixel. Since clouds come and go, the median pixel is not likely to be cloudy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fe1fa1-5260-40b3-b015-a577c4a758a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "median = data.median(dim=\"time\")\n",
    "median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ca2f48-e628-467c-adb6-e6f544dfd333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xrspatial.multispectral\n",
    "\n",
    "image = xrspatial.multispectral.true_color(\n",
    "    *median\n",
    ")\n",
    "image = image.chunk({\"x\": 710, \"y\": 710}).persist()\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d6c1a2-9b00-43b7-84ce-462321c2b3fb",
   "metadata": {},
   "source": [
    "stackstac has a handy `show` method to help visualize data that's on a cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07aa50c8-6078-4235-9352-ca836567e283",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyleaflet import FullScreenControl\n",
    "\n",
    "m = stackstac.show(\n",
    "    image.assign_coords(epsg=data.coords[\"epsg\"]).isel(band=slice(3)),\n",
    "    range=[40, 255]\n",
    ")\n",
    "m.scroll_wheel_zoom = True\n",
    "m.add_control(FullScreenControl())\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a394d5ab-c46a-4bae-8e69-ddc925db60b3",
   "metadata": {},
   "source": [
    "That was nice, but we have all the power of a mature, domain-agnostic library like xarray! For example, suppose you don't want to combine images from January with images from July (you want to see snowy areas, for example). xarary provides a nice, high-level API to do just that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0869b727-8a13-4437-864e-3285a1e0bdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly = data.groupby(\"time.month\").median().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b304bd5-c38d-4773-8125-55ac2a2ddc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab83b8c-0cc0-4cb7-81d5-7311a6a79235",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [\n",
    "    xrspatial.multispectral.true_color(*x) for x in monthly\n",
    "]\n",
    "images = xr.concat(images, dim=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ae240e-f096-4bc4-87a3-28b9195802f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = images.plot.imshow(\n",
    "    x=\"x\", y=\"y\", rgb=\"band\", col=\"time\", col_wrap=3, figsize=(12, 16)\n",
    ")\n",
    "for ax in g.axes.flat:\n",
    "    ax.set_axis_off()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3577d6-fd0b-4e16-b3c2-4be3840ffae3",
   "metadata": {},
   "source": [
    "# Animatring Hurricane Florence\n",
    "\n",
    "This example builds off an example from the [pytroll documentation](https://github.com/pytroll/pytroll-examples/blob/main/satpy/GOES-16%20ABI%20-%20True%20Color%20Animation%20-%20Hurricane%20Florence.ipynb). We'll make a short animation of Hurricane Florence as it moves across the Atlantic Ocean, using the [GOES-R Cloud & Moisture Imagery](https://planetarycomputer.microsoft.com/dataset/goes-cmi) product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720eea29-78a5-4148-9c14-6bb2fef4e722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "import contextily as ctx\n",
    "import geopandas\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import planetary_computer\n",
    "import pystac_client\n",
    "import rioxarray\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c09149-c08a-49be-86f8-80cbd8b1f27f",
   "metadata": {},
   "source": [
    "NOAA maintains a database of \"storm tracks\" which show the path that hurricanes and tropical storms take. We'll use it to find the position of Hurricane Florence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4887856a-33b1-4c61-b2f5-f71c51023dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file, _ = urllib.request.urlretrieve(\n",
    "    \"https://www.ncei.noaa.gov/data/international-best-track-archive-for-\"\n",
    "    \"climate-stewardship-ibtracs/v04r00/access/netcdf/IBTrACS.NA.v04r00.nc\"\n",
    ")\n",
    "# The storm id comes from the text file in\n",
    "# https://www.ncei.noaa.gov/data/international-best-track-archive-for-climate-stewardship-ibtracs\n",
    "# /v04r00/access/netcdf/\n",
    "# The name of this file changes with the update date, so we can't access it programatically.\n",
    "STORM_ID = b\"2018242N13343\"\n",
    "ds = xr.open_dataset(file)\n",
    "storm_loc = (ds.sid == STORM_ID).argmax().item()\n",
    "\n",
    "florence_data = ds.sel(storm=storm_loc)\n",
    "florence_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdff487a-63eb-43dd-b306-41e51c91e4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    geopandas.GeoDataFrame(\n",
    "        dict(\n",
    "            time=pd.to_datetime(florence_data.time).tz_localize(\"UTC\"),\n",
    "            geometry=geopandas.points_from_xy(florence_data.lon, florence_data.lat),\n",
    "        )\n",
    "    )\n",
    "    .set_crs(4326)\n",
    "    .dropna()\n",
    ")\n",
    "\n",
    "start = pd.Timestamp(\"2018-09-11T13:00:00Z\")\n",
    "stop = pd.Timestamp(\"2018-09-11T15:40:00Z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835af069-e38b-42bd-97bd-a47b1099161e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df.to_crs(epsg=3857).plot(figsize=(12, 12))\n",
    "subset = df[df.time.dt.date == start.date()]\n",
    "subset.to_crs(epsg=3857).plot(ax=ax, color=\"r\")\n",
    "\n",
    "ctx.add_basemap(ax)\n",
    "ax.set_axis_off()\n",
    "ax.set(title=\"Path of Hurricane Florence (animation period in red)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4784af91-60cb-4286-87c0-a9446424b849",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = list(subset.total_bounds)\n",
    "bbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72466165-aaa1-4ec1-93b4-856d75b9ddec",
   "metadata": {},
   "source": [
    "With those timestamps and bounding-box, we can do our search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a525c0f5-9b56-4083-beb5-ca9d0e3dd250",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1/\"\n",
    ")\n",
    "search = catalog.search(\n",
    "    collections=[\"goes-cmi\"],\n",
    "    bbox=bbox,\n",
    "    datetime=[start, stop],\n",
    "    query={\"goes:image-type\": {\"eq\": \"MESOSCALE\"}},\n",
    ")\n",
    "items = search.get_all_items()\n",
    "signed_items = sorted(\n",
    "    [planetary_computer.sign(item) for item in items], key=lambda x: x.datetime\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4692511e-b385-41f8-ac97-d72588cd6927",
   "metadata": {},
   "source": [
    "GOES doesn't have an epsg code, so it can't be read with `stackstac`. But `rioxarray` is a very flexible library for reading this raster data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b837f3a-e7ed-424c-ba09-bf158929e74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = rioxarray.open_rasterio(signed_items[0].assets[\"C01_2km\"].href).load()\n",
    "ds[0].plot.imshow(figsize=(16, 9), cmap=\"Blues\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7269cc2d-61bc-4ef4-b31f-cb3582de82a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = [\"C01_2km\", \"C02_2km\", \"C03_2km\"]\n",
    "common_names = [\n",
    "    items[0].assets[band].extra_fields[\"eo:bands\"][0][\"common_name\"] for band in bands\n",
    "]\n",
    "time = xr.DataArray(\n",
    "    pd.to_datetime([x.datetime for x in signed_items]).tz_localize(None),\n",
    "    name=\"time\",\n",
    "    dims=[\"time\"],\n",
    ")\n",
    "\n",
    "item = signed_items[0]\n",
    "arrays = [rioxarray.open_rasterio(item.assets[band].href, chunks=True) for band in bands]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fb3cb3-a12d-4b6d-af6a-b9d0e4dd7364",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "arrays = [\n",
    "    xr.concat(\n",
    "        [rioxarray.open_rasterio(item.assets[band].href, chunks=True)\n",
    "         for band in bands], dim=\"band\"\n",
    "    ).assign_coords(band=common_names)\n",
    "    for item in signed_items\n",
    "]\n",
    "data = xr.concat(arrays, dim=time).rename(\"goes\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9a4d85-071f-4361-b456-1303210df211",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b0ff14-327c-44d3-88b0-44ad4cb40ee3",
   "metadata": {},
   "source": [
    "GOES doesn't have a green band, so we simulate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878df954-e48f-45f6-b9bf-d8f442e9a597",
   "metadata": {},
   "outputs": [],
   "source": [
    "green = (\n",
    "    0.45 * data.sel(band=\"red\")\n",
    "    + 0.1 * data.sel(band=\"nir09\")\n",
    "    + 0.45 * data.sel(band=\"blue\")\n",
    ").assign_coords(band=\"green\")\n",
    "green"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f4e951-e128-41fd-bdb0-2ce9175dc9cc",
   "metadata": {},
   "source": [
    "And we apply a gamma-correction to make the picture prettier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26410b2-d221-43ef-8dc6-42efd4cdd1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "γ = 2.2\n",
    "\n",
    "rgb = xr.concat([data, green], dim=\"band\").sel(band=[\"red\", \"green\", \"blue\"])\n",
    "rgb = rgb / rgb.max(dim=[\"band\", \"y\", \"x\"])\n",
    "rgb = rgb ** (1 / γ)\n",
    "rgb = rgb.where(lambda x: x > 0, 0).where(lambda x: x < 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c140aa4-feb6-4194-860e-375290daea8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = rgb.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8ed82f-5be1-4ce9-911a-5018e587d05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 16))\n",
    "rgb.isel(time=0).plot.imshow(rgb=\"band\", add_labels=False)\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46216c81-dd6f-4ebe-af2f-24c2686d823d",
   "metadata": {},
   "source": [
    "Now we animate this stack of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1de92ec-893b-43ae-8946-220153f97104",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 16))\n",
    "fig.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=None, hspace=None)\n",
    "ax.set_axis_off()\n",
    "\n",
    "img = rgb[0].plot.imshow(ax=ax, add_colorbar=False, rgb=\"band\", add_labels=False)\n",
    "label = ax.text(\n",
    "    0.4,\n",
    "    0.03,\n",
    "    pd.Timestamp(rgb.time.data[0]).isoformat(),\n",
    "    transform=ax.transAxes,\n",
    "    color=\"k\",\n",
    "    size=20,\n",
    ")\n",
    "\n",
    "def animate(i):\n",
    "    img.set_data(rgb[i].transpose(\"y\", \"x\", \"band\"))\n",
    "    label.set_text(pd.Timestamp(rgb.time.data[i]).isoformat())\n",
    "    return img, label\n",
    "\n",
    "\n",
    "ani = animation.FuncAnimation(fig, animate, frames=len(rgb), interval=120)\n",
    "ani.save(\n",
    "    \"goes.mp4\",\n",
    "    fps=15,\n",
    "    extra_args=[\"-vcodec\", \"libx264\"],\n",
    "    savefig_kwargs=dict(pad_inches=0, transparent=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393fd9a8-d0c0-4093-bee0-17d79209f8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "Video(\"goes.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e6776f-fe9c-4201-a4d3-10d51b2f899a",
   "metadata": {},
   "source": [
    "A pre-rendered version: https://ai4edatasetspublicassets.blob.core.windows.net/assets/pc_video/pc-examples-goes-florence.webm.\n",
    "\n",
    "A couple things to highlight:\n",
    "\n",
    "1. Once we had the date and times in geopandas, finding the right STAC items was pleasent\n",
    "\n",
    "```python\n",
    "search = catalog.search(\n",
    "    collections=[\"goes-cmi\"],\n",
    "    bbox=bbox,\n",
    "    datetime=[start, stop],\n",
    "    query={\"goes:image-type\": {\"eq\": \"MESOSCALE\"}},\n",
    ")\n",
    "```\n",
    "\n",
    "2. xarray's named axes are great! It's much nicer to use `\"red\"`, `\"nir\"` than `0`, `1`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
